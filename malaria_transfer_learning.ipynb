{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j6wBHwwLh6L"
      },
      "source": [
        "#### Imports, check that GPU is used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! nvcc  --version\n",
        "! pip install tensorflow keras --quiet\n",
        "! pip install keras-tuner --quiet\n",
        "! pip install keras-applications\n",
        "! pip install seaborn --quiet\n",
        "! pip install kaggle --quiet\n",
        "\n",
        "! pip install pyyaml h5py  # Required to save models in HDF5 format\n",
        "\n",
        "# needed for AugMix (removed)\n",
        "# !pip install keras-cv --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-u8AbdXIAZX",
        "outputId": "bf7723d0-d59f-4445-af65-ff5ff5968b21"
      },
      "outputs": [],
      "source": [
        "# dataset\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import collections\n",
        "\n",
        "# model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.applications import MobileNetV3Large\n",
        "\n",
        "import keras_tuner as kt\n",
        "# from keras_cv.layers import AugMix\n",
        "\n",
        "# graphs/stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ySrsXTIFLMQ1",
        "outputId": "db28396f-e715-4054-a626-3a0aaa9d004b"
      },
      "outputs": [],
      "source": [
        "# confirm TensorFlow sees the GPU\n",
        "from tensorflow.python.client import device_lib\n",
        "#assert 'GPU' in str(device_lib.list_local_devices())\n",
        "#assert len(tf.config.list_physical_devices('GPU')) > 0\n",
        "\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG6HOdXmIv4U"
      },
      "source": [
        "### Dataset preparation\n",
        "\n",
        "The dataset contains 2 folders\n",
        "*   Infected\n",
        "*   Parasitized\n",
        "And a total of 27,558 images.\n",
        "Acknowledgements\n",
        "This Dataset is taken from the official NIH Website: https://ceb.nlm.nih.gov/repositories/malaria-datasets/\n",
        "And uploaded here, so anybody trying to start working with this dataset can get started immediately, as to download the\n",
        "dataset from NIH website is quite slow.\n",
        "\n",
        "1. kaggle automatic download\n",
        "2. load and split the dataset in train/val (80/20) & getting label names\n",
        "3. compute dataset statistics\n",
        "4. dataset standardization\n",
        "5. dataset augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gObvVCJeJk7E"
      },
      "source": [
        "#### Loading, splitting, standardizing the dataset and getting class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X3C1PIfbEE4T"
      },
      "outputs": [],
      "source": [
        "# dataset folder\n",
        "directory = \"./cell_images\"\n",
        "\n",
        "filepath = []\n",
        "label = []\n",
        "\n",
        "folds = os.listdir(directory)\n",
        "\n",
        "for fold in folds:\n",
        "    f_path = os.path.join(directory, fold)\n",
        "    imgs = os.listdir(f_path)\n",
        "    for img in imgs:\n",
        "        img_path = os.path.join(f_path, img)\n",
        "        filepath.append(img_path)\n",
        "        label.append(fold)\n",
        "\n",
        "# Concatenate data paths with labels\n",
        "file_path_series = pd.Series(filepath, name='filepath')\n",
        "Label_path_series = pd.Series(label, name='label')\n",
        "df_train = pd.concat([file_path_series, Label_path_series], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bdB5p9HOOxp"
      },
      "outputs": [],
      "source": [
        "# splitting the dataset and getting class names\n",
        "img_height = 224 # UPDATED FOR MOBILENET\n",
        "img_width = 224 # UPDATED FOR MOBILENET\n",
        "batch_size = 32\n",
        "SEED = 123 # for reproducibility\n",
        "\n",
        "# training, test set split\n",
        "# resizing already handled by TensorFlow\n",
        "# no need to reshape\n",
        "\n",
        "print('Loading and splitting the tf_dataset')\n",
        "train_set, test_set = keras.utils.image_dataset_from_directory(\n",
        "  directory,\n",
        "  validation_split=0.2,  # 80/20%\n",
        "  subset=\"both\",\n",
        "  # shuffle=False,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  label_mode='binary'    # parasitized/uninfected\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFnTrNRkMXBh"
      },
      "outputs": [],
      "source": [
        "# getting the class names\n",
        "classes = train_set.class_names\n",
        "num_classes = len(classes)\n",
        "print(f'[0={classes[0]}, 1={classes[1]}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OL65CRjARcn"
      },
      "source": [
        "The images need to be standardized, so we use a lambda function to standardize them so that they have values in (0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X99rjMZfk_f"
      },
      "outputs": [],
      "source": [
        "# train_set = train_set.map(lambda x, y: (x/255, y))\n",
        "test_set = test_set.map(lambda x, y: (x/255, y))\n",
        "\n",
        "for image, _ in train_set.take(5):\n",
        "    img = image.numpy()\n",
        "    print(\"Image shape:\", img.shape)\n",
        "    print(\"Pixel value range: min =\", img.min(), \", max =\", img.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ0wVJuAdSlc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# calculates how many images there are for each class\n",
        "def num_img_per_class(dataset):\n",
        "  class_counts = collections.Counter()\n",
        "  for _, labels in dataset:\n",
        "      class_indices = labels.numpy().squeeze().astype(int)  # (batch_size, 1) â†’ (batch_size,)\n",
        "      class_counts.update(map(int, class_indices))\n",
        "  return class_counts\n",
        "\n",
        "# Get counts\n",
        "train_class_counts = num_img_per_class(train_set)\n",
        "val_class_counts = num_img_per_class(test_set)\n",
        "print('Training set:', train_class_counts)\n",
        "print('Validation set:', val_class_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhvFxqx8fSek"
      },
      "outputs": [],
      "source": [
        "# bar diagram of training and validation classes distribution\n",
        "labels_map = {0: 'Parasitized', 1: 'Uninfected'}\n",
        "\n",
        "# Prepare data\n",
        "x_labels = [labels_map[i] for i in sorted(labels_map.keys())]\n",
        "x_pos = range(len(x_labels))\n",
        "train_vals = [train_class_counts[i] for i in sorted(labels_map.keys())]\n",
        "val_vals = [val_class_counts[i] for i in sorted(labels_map.keys())]\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot bars\n",
        "bar_width = 0.35\n",
        "bars1 = plt.bar([i - bar_width/2 for i in x_pos], train_vals, width=bar_width, label='Training', color='skyblue')\n",
        "bars2 = plt.bar([i + bar_width/2 for i in x_pos], val_vals, width=bar_width, label='Test', color='orange')\n",
        "\n",
        "# Add counts on top of bars\n",
        "for bar in bars1 + bars2:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, height + 100, f'{height}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "# Final touches\n",
        "plt.xticks(ticks=x_pos, labels=x_labels)\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.title(\"Class Distribution in Training vs Test Set\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgKA9mi2hk6F"
      },
      "source": [
        "As you can see the class distribution is almost identical both for the training set and test set.\n",
        "We will now show some images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o5SQYqQXU8u"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for images, labels in train_set.take(1):\n",
        "    num_images = batch_size  # Show more images\n",
        "    for i in range(num_images):\n",
        "        ax = plt.subplot(4, 8, i+1)  # 4x8 grid\n",
        "        plt.imshow((images[i].numpy()).astype(\"uint8\"))\n",
        "        plt.title(classes[int(labels[i].numpy())], fontsize=6)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.subplots_adjust(hspace=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKHRbGgQiv8w"
      },
      "source": [
        "#### Data augmentation (custom pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shHNKwOrkJ0a"
      },
      "source": [
        "We will now extend (double) the training dataset by adding images obtained with various data augmentation techniques. The augmented dataset is merged with the training set to enalrge it. At last, the merged dataset is normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPPKZMhCizV-",
        "outputId": "303d0c7f-0d00-4681-9135-3cbdfe208353"
      },
      "outputs": [],
      "source": [
        "\n",
        "# we have discovered that AugMix, which has great theoretical performances does not work well\n",
        "# on our medical images as it introduces too many color variations, so we moved to a more\n",
        "# conventional data augmentation pipeline\n",
        "# AugMix(\n",
        "#         severity=1,\n",
        "#         chain_depth=1,\n",
        "#         alpha=0.1,\n",
        "#         value_range=(0, 255),\n",
        "#     ),\n",
        "# see https://arxiv.org/abs/1912.02781 for details on AugMix\n",
        "\n",
        "preprocessing = keras.Sequential([\n",
        "    # geometric transformations\n",
        "    layers.RandomRotation(factor=0.2),\n",
        "    layers.RandomFlip(mode='horizontal_and_vertical'),\n",
        "\n",
        "    # illumination transformations\n",
        "    layers.RandomBrightness(factor=0.15),\n",
        "    layers.RandomContrast(factor=0.15),\n",
        "\n",
        "    # some noise\n",
        "    layers.GaussianNoise(stddev=0.05),\n",
        "    #layers.Rescaling(1./255), # data standardization\n",
        "])\n",
        "\n",
        "augmented_dataset = train_set.map(lambda x, y: (preprocessing(x), y))\n",
        "# concatenate the two datasets to form a big one\n",
        "train_set = train_set.concatenate(augmented_dataset)\n",
        "\n",
        "print('Augmented train set size:', augmented_dataset.cardinality().numpy()*batch_size)\n",
        "print('Merged train set size:', train_set.cardinality().numpy()*batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do not rerun this cell on its own otherwise the dataset doubles each time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmDYbAQ4BPsY"
      },
      "source": [
        "Now we standardize the training set as well as the merged dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeKVgz0JBTec",
        "outputId": "11e36fbe-8ce4-45c3-f323-5448d3a0b59d"
      },
      "outputs": [],
      "source": [
        "train_set = train_set.map(lambda x, y: (x/255, y))\n",
        "\n",
        "for image, _ in train_set.take(5):\n",
        "    img = image.numpy()\n",
        "    print(\"Image shape:\", img.shape)\n",
        "    print(\"Pixel value range: min =\", img.min(), \", max =\", img.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFm4bm-SBZyr"
      },
      "source": [
        "The images are preprocessed and standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "vJrissCV31WL",
        "outputId": "f45c0c43-6009-4c76-c59f-35219e5c405f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for images, labels in train_set.take(1):\n",
        "    num_images = batch_size  # Show more images\n",
        "    for i in range(num_images):\n",
        "        ax = plt.subplot(4, 8, i+1)  # 4x8 grid\n",
        "        plt.imshow((images[i].numpy() * 255).astype(\"uint8\"))\n",
        "        plt.title(classes[int(labels[i].numpy())], fontsize=6)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "plt.subplots_adjust(hspace=0)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co6FmJpmB-3y"
      },
      "source": [
        "As you can see the images are changed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transfer learning using MobileNetV3 & KerasTuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Build the model replacing the top layers of MobileNetV3 with custom ones\n",
        "2. Use KerasTuner to select the best number of neurons \n",
        "3. Retrain the model on the entire train_set\n",
        "4. Evaluate the model's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_builder(hp):\n",
        "    input_shape = (224, 224, 3) # Height, Width, Channels (RGB)\n",
        "    mobile_net = keras.applications.MobileNetV3Large(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    mobile_net.trainable = False\n",
        "\n",
        "    model = keras.Sequential()\n",
        "    model.add(mobile_net) # add MobileNetV3 to base model\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "\n",
        "    # Tune the number of units in the first dense layer\n",
        "    neurons = [hp.Int('units_1', min_value=64, max_value=512, step=64), hp.Int('units_2', min_value=64, max_value=512, step=64)]\n",
        "    drops = [hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.05), hp.Float('dropout_2', min_value=0.0, max_value=0.5, step=0.05)]\n",
        "\n",
        "    num_layers = hp.Choice('num_layers', values=[1,2])\n",
        "    for i in range(num_layers):\n",
        "        model.add(layers.Dense(units=neurons[i], activation='relu'))\n",
        "        # tune dropout rate \n",
        "        model.add(layers.Dropout(rate=drops[i]))\n",
        "\n",
        "    # Output layer for binary classification\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # tune the optimizer\n",
        "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop'])\n",
        "    lrate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-1, sampling='LOG')\n",
        "\n",
        "    # defaults to adam\n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    match optimizer_choice:\n",
        "        case 'adam':\n",
        "            optimizer = keras.optimizers.Adam(learning_rate=lrate)\n",
        "        case 'sgd':\n",
        "            optimizer = keras.optimizers.SGD(learning_rate=lrate)\n",
        "        case 'rmsprop':\n",
        "            optimizer = keras.optimizers.RMSprop(learning_rate=lrate)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split train into train_reduced/val\n",
        "train_size = int(train_set.cardinality().numpy() * 0.8)\n",
        "train_reduced = train_set.take(train_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_set = train_set.skip(train_size).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# 3. Verify the split (Optional)\n",
        "print(\"Reduced training dataset size:\", train_reduced.cardinality().numpy()*batch_size)\n",
        "print(\"Validation dataset size:\", val_set.cardinality().numpy()*batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(\n",
        "    hypermodel=model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=5,\n",
        "    factor = 3,\n",
        "    directory = 'tuned_models',\n",
        "    project_name='malaria_transfer_learning'\n",
        ")\n",
        "\n",
        "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
        "tuner.search(train_reduced, epochs=50, validation_data=val_set, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Re-train the best model on the entire train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cache and prefetch for faster training\n",
        "train_set = train_set.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_set = test_set.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the best model\n",
        "best_params = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# create the best model found\n",
        "best_model = tuner.hypermodel.build(best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we Fine-Tune the MobileNet model to improve the performance on our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# retrain the best model on the entire training set\n",
        "# unfreeze MobileNetV3\n",
        "best_model.layers[0].trainable = True\n",
        "\n",
        "fine_tune_lr=1e-4\n",
        "best_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=fine_tune_lr),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "stop_early = keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "history = best_model.fit(train_set, epochs=10, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "if you want to avoid retraining (very long process) here are the statistics\n",
        "training accuracy: 0.9682 - loss: 0.0921"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the model in an h5 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "! mkdir -p saved_model\n",
        "keras.saving.save_model(best_model, 'saved_model/malaria_mobile_net.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing the model on the test_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make this code runnable even without retraining the model we load it from the saved file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load on the same variable to save memory\n",
        "best_model = keras.saving.load_model('saved_model/malaria_mobile_net.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After training the model we have achieved a training accuracy of 0.96.. (hardcoded value! may vary slighly), we now test it on the test_set to get an estimate of the generalization error. It may take a while as the test set is composed of more than 5K images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate it on the test set\n",
        "loss, accuracy = best_model.evaluate(test_set, verbose=0)\n",
        "\n",
        "print(f'Best model test loss: {loss:.4f}')\n",
        "print(f'Best model test accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Some model stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Precision/Recall/F1-score and AUC-ROC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once again this operation may take a while as the test set is composed of lots of images!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# testing the model performance on the test_set\n",
        "# to get an estimate of the generalization error\n",
        "y_true = []\n",
        "y_probs = []\n",
        "\n",
        "for x_batch, y_batch in test_set:\n",
        "    preds = best_model.predict(x_batch, verbose=0).ravel()\n",
        "    y_probs.extend(preds)\n",
        "    y_true.extend(y_batch.numpy())\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_probs = np.array(y_probs)\n",
        "y_pred = (y_probs > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_true, y_pred, target_names=['Uninfected', 'Parasitized']))\n",
        "print(f\"AUC-ROC: {roc_auc_score(y_true, y_probs):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_true, y_probs):.4f}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the precision/recall curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(recall, precision, color='purple')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Uninfected', 'Parasitized'],\n",
        "            yticklabels=['Uninfected', 'Parasitized'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FAjqlxqb8PwV",
        "gObvVCJeJk7E",
        "vm38fIg0XReC",
        "nR5MVf5E4M61"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
